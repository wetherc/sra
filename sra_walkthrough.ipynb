{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from typing import List, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame({\n",
    "    'sex': ['M', 'M'],\n",
    "    'marital': ['S', 'M'],\n",
    "    'homeowner': ['Y', 'N']\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overlapping Simlarity\n",
    "\n",
    "Given two `n`-dimensional feature vectors, `x` and `y`, overlapping similarity is given by\n",
    "\n",
    "$$\n",
    "s^{O}(x, \\widetilde{x}) = 1 - d^{H}(x, \\widetilde{x})\n",
    "$$\n",
    "\n",
    "where $d^{H}(x, \\widetilde{x})$ is the Hamming distance defined as the number of features that $x$ and $\\widetilde{x}$ do not match, divided by the total number of features:\n",
    "\n",
    "$$\n",
    "d^{H}(x, \\widetilde{x}) = \\frac{\\sum_{i=1}^{n}\\delta(x_{i}, \\widetilde{x}_{i})}{n}\n",
    "$$\n",
    "\n",
    "where\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\delta(x_{i}, \\widetilde{x}_{i}) = \\begin{cases}\n",
    "    1, & x_{i} \\neq \\widetilde{x}_{i} \\\\\n",
    "    0, & x_{i} = \\widetilde{x}_{i}\n",
    "\\end{cases}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "By way of example, in the following dataset we have two feature vectors (i.e., two different observations). Both are male, but differ in marital status and homeowner status:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>marital</th>\n",
       "      <th>homeowner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>S</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sex marital homeowner\n",
       "0   M       S         Y\n",
       "1   M       M         N"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do the pairwise features differ? [False, True, True]\n",
      "Hamming distance between two observations: 0.6666666666666666\n",
      "Overlapping similarity: 0.33333333333333337\n"
     ]
    }
   ],
   "source": [
    "feature_difference = list(data.loc[0,:] != data.loc[1,:])\n",
    "print(f'Do the pairwise features differ? {feature_difference}')\n",
    "\n",
    "hamming_distance = sum(feature_difference) / data.shape[1]\n",
    "print(f'Hamming distance between two observations: {hamming_distance}')\n",
    "\n",
    "overlapping_similarity = 1 - hamming_distance\n",
    "print(f'Overlapping similarity: {overlapping_similarity}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weighted Hamming Distance\n",
    "\n",
    "Rather than averaging across all features in the vector, we can instead use a weighted measure that averages on a per-feature basis with respect to the number of distinct values that the specific feature can take on:\n",
    "$$\n",
    "d^{WH}(x, \\widetilde{x}) = \\sum_{i=1}^{n}\\frac{\\delta(x_{i}, \\widetilde{x}_{i})}{|\\mathcal{D}_{i}|}\n",
    "$$\n",
    "\n",
    "where $|\\mathcal{D}_{i}|$ is the _number_ of distinct possible values that a particular feature is able to assume. (E.g., for homeowner, there would be a cardinality of $2$ since you either are or are not a homeowner.) Applying this weighted distance to the above dataset yields:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of distinct possible values for each feature: sex          1\n",
      "marital      2\n",
      "homeowner    2\n",
      "dtype: int64\n",
      "Do the pairwise features differ? [False  True  True]\n",
      "Weighted Hamming distance between two observations: 1.0\n"
     ]
    }
   ],
   "source": [
    "cardinality = data.nunique()\n",
    "print(f'Number of distinct possible values for each feature: {cardinality}')\n",
    "\n",
    "feature_difference = np.array(data.loc[0,:] != data.loc[1,:])\n",
    "print(f'Do the pairwise features differ? {feature_difference}')\n",
    "\n",
    "w_hamming_distance = sum(feature_difference / cardinality)\n",
    "print(f'Weighted Hamming distance between two observations: {w_hamming_distance}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that in the above, we can no longer use the overlapping similarity metric defined previously since our weighted Hamming distance is no longer bounded on a $[0, 1]$ interval.\n",
    "\n",
    "# Extension to a Kernel\n",
    "\n",
    "A kernel function, or a kernel trick, at a high level is a mapping of data into a higher-dimensional, implicit feature space such that we can identify a hyperplane in which our data are linearly separable. Intuitively, the mapping can be visualized as:\n",
    "\n",
    "![](./assets/kernel.png)\n",
    "\n",
    "> Kernel methods apply standard machine learning algorithms that rely on distance metrics or inner products to data embedded into a feature space using kernel functions. The embedding of the data into a feature space is expected to capture and enhance the patterns and regularities in the data. Kernel methods proceed in two steps. The first step embeds the data into a feature space of high or infinite dimension, while the second step uses standard algorithms for classification, clustering, and principal component analysis to detect the regularities of the data in the feature space. The core of kernel methods relies on the use of kernel functions. A kernel function computes the inner product in a feature space of the embedding of two data points under a certain mapping, $\\phi$\n",
    "\n",
    "We can extend our Hamming distance to apply to a Gaussian kernel, by replacing Euclidean distance with it:\n",
    "$$\n",
    "k^{GH}(x, \\widetilde{x}) = e^{-\\frac{\\delta(x, \\widetilde{x})}{2\\sigma^{2}}}\n",
    "$$\n",
    "where $\\sigma > 0$ is a constant kernel width parameter.\n",
    "\n",
    "## Adaptive Gaussian Kernel\n",
    "\n",
    "In the above, $\\sigma$ is a constant parameter. We can, however, use an adaptive bandwidth parameter:\n",
    "$$\n",
    "k^{GH}(x, \\widetilde{x}) = e^{-\\frac{\\delta(x, \\widetilde{x})}{\\beta(x,\\widetilde{x})}}\n",
    "$$\n",
    "where $\\beta(x, \\widetilde{x})$ is an adaptive bandwidth determined by a fixed number of nearest neighbors of data instance $x$ and $\\widetilde{x}$.\n",
    "\n",
    "## Hamming Distance Kernel\n",
    "\n",
    "We can extend the above to a Hamming Distance Kernel, in which we consider $\\mathcal{D}^{n}$ to be the cross product over all $n$ input features. Formally, we can define this by\n",
    "\n",
    "_Let $D_{i}$ by a finite domain of categorical values. Let $(a_{1}, \\ldots, a_{n})$ by a categorical object such that $a_{i}\\in D_{i}$. Let $D^{n}=\\prod_{i=1}^{n}D_{i}$ be the cross product over all the domains of the attributes such that for each $(u_{1}, \\ldots, u_{n})\\in D^{n}$, $u_{i}\\in D_{i}$. Given a categorical object $s = (s_{1}, \\ldots, s_{n})$, $s_{k}$ denotes the value of the $k$-th attribute of $s$_\n",
    "\n",
    "To start, we begin be again ensuring that our columns are defined as categorical and then dummy encoding them to integers. I will also initialize an all-ones `NxN` kernel matrix where `N` is equal to the length of my dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame({\n",
    "    'sex': ['M', 'M', 'F'],\n",
    "    'marital': ['S', 'M', 'S'],\n",
    "    'homeowner': ['Y', 'N', 'Y']\n",
    "}, dtype='category')\n",
    "data = data.apply(lambda x: x.cat.codes)\n",
    "\n",
    "cardinality = data.nunique()\n",
    "damping_param = 0.6\n",
    "n = data.shape[0]\n",
    "k_j = np.ones(shape=(n, n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each observation in the dataset, we can now compute its hamming distance from every other observation in the dataset and compute the recursive kernel step as\n",
    "$$\n",
    "\\begin{align}\n",
    "k^{0}(x, \\widetilde{x}) &= 1 \\\\\n",
    "k^{j}(x, \\widetilde{x}) &= (\\lambda^{2}(|\\mathcal{D}_{j}| - 1 - \\delta(x_{j},\\widetilde{x}_{j}))+(2\\lambda - 1)\\delta(x_{j}, \\widetilde{x}_{j} + 1)k^{j-1}(x, \\widetilde{x})\n",
    "\\end{align}\n",
    "$$\n",
    "for all values of $j = 1, \\ldots, n$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.515456, 1.9584  , 2.21952 ],\n",
       "       [1.9584  , 2.515456, 1.728   ],\n",
       "       [2.21952 , 1.728   , 2.515456]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for col in range(len(cardinality)):\n",
    "    dhamming_j = np.not_equal.outer(\n",
    "        data.iloc[:, col].values,\n",
    "        data.iloc[:, col].values\n",
    "    )\n",
    "    k_j = (\n",
    "        (damping_param**2) * (cardinality[col] - 1 - dhamming_j) +\n",
    "        (2 * damping_param - 1) * dhamming_j + 1) * k_j\n",
    "    \n",
    "k_j"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spectral Ranking\n",
    "\n",
    "Now that we have a kernel matrix, we need to construct both an adjacency matrix, $W$, and a degree matrix, $D$. The adjacency matrix allows us to represent the data using an undirected graph $G=(V,E)$, with vertices $V=\\{v_{1}, v_{2}, \\ldots, v_{n}\\}$ corresponding to data instances (i.e., the rows and columns), and the cell values corresponding to the edges connecting each vertex to another. This allows us to summarize the similarity between two corresponding data instances, where $W_{ij}$ is the similarity between $v_{i}$ and $v_{j}$.\n",
    "\n",
    "To construct this adjacency matrix, we will normalize our kernel matrix such that the diagonal (a comparison of any observation against itself) is equal to $1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.77854671 0.88235294]\n",
      " [0.77854671 1.         0.68695298]\n",
      " [0.88235294 0.68695298 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "kern_diag = 1 / np.sqrt(np.diag(k_j))\n",
    "W = k_j * np.outer(kern_diag, kern_diag)\n",
    "print(W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then construct a degree vector $d$ of each vertex with $x_{i} = \\sum_{j}W_{ij}$ (i.e., the row sum for the observation), and from that create a degree matrix, $D$, with $d$ on the diagonal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.693376, 0.      , 0.      ],\n",
       "       [0.      , 6.201856, 0.      ],\n",
       "       [0.      , 0.      , 6.462976]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = W.shape[0]\n",
    "ident = np.zeros((n, n), float)\n",
    "np.fill_diagonal(ident, 1.)\n",
    "\n",
    "# Let D be the degree matrix of each vertex corresponding\n",
    "# the the row sum of the similarity matrix W\n",
    "d = np.sum(k_j, axis=1)\n",
    "D = np.zeros((n, n), float)\n",
    "np.fill_diagonal(D, d)\n",
    "D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having done this, we will now create a symmetric normalized Laplacian, $L=I - D^{-1/2}WD^{-1/2}$ where $I$ is an identity matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.85059856, -0.12083736, -0.13415395],\n",
       "       [-0.12083736,  0.83875795, -0.10850504],\n",
       "       [-0.13415395, -0.10850504,  0.84527252]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D_inv_sqrt = np.linalg.inv(np.sqrt(D))\n",
    "\n",
    "# Let L be the symmetric normalized Laplacian\n",
    "L = ident - np.dot(D_inv_sqrt, W).dot(D_inv_sqrt)\n",
    "L"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now extract the first and second non-principal eigenvectors for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.2149818 , -0.77975547],\n",
       "       [-0.79803158,  0.20681425],\n",
       "       [ 0.56296396,  0.59093932]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract the 2 non-principal eigenvectors.\n",
    "#\n",
    "# The eig() function returns 2 arrays: the\n",
    "# first represents eigenvalues, the second\n",
    "# eigenvectors. The eigenvectors are not\n",
    "# arranged in order of magnitude. We sort\n",
    "# and then sample the second and third vectors\n",
    "eig_vals, eig_vecs = np.linalg.eig(L)\n",
    "eig_vecs = eig_vecs[:, eig_vals.argsort()[::][1:]]\n",
    "eig_vecs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The authors also define a bi-class clustering strength measure $z^{*} = D^{1/2}g_{1}^{*}$ where $g^{*}$ is the first non-principal eigenvector for the normalized spectral optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.55619144, -1.98738002,  1.43118858])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Components of the first non-principal\n",
    "# eigenvectors in the feature space.\n",
    "#\n",
    "# Note that here we're just duplicating\n",
    "# D_sqrt column-wise so that its dimensionality\n",
    "# is equal to that of npeigen\n",
    "z = np.sqrt(d) * eig_vecs[:, 0]\n",
    "z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can delineate between the normal case and cases where only one major pattern exists:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.55619144,  1.98738002, -1.43118858])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let C_p be the positive class and and C_n\n",
    "# the negative class assigned based on the\n",
    "# sign of the 1st non-principal eigenvector\n",
    "# component of z\n",
    "C = np.sign(z)\n",
    "C_cnt = np.unique(C, return_counts=True)\n",
    "C_cnt = pd.DataFrame(\n",
    "    data=np.array(C_cnt[1])[np.newaxis],\n",
    "    columns=C_cnt[0])\n",
    "\n",
    "if C_cnt.iloc[[0]].min(axis=1)[0]/n >= 0.4:\n",
    "    mFLAG = 1\n",
    "    f = np.max(np.abs(z)) - np.abs(z)\n",
    "else:\n",
    "    if C_cnt[1][0] > C_cnt[-1][0]:\n",
    "        mFLAG = 0\n",
    "        f = -z\n",
    "    else:\n",
    "        mFLAG = 0\n",
    "        f = z\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "p = plt.scatter(\n",
    "    x=eig_vecs[:, 1],\n",
    "    y=eig_vecs[:, 0],\n",
    "    c=f,\n",
    "    cmap='seismic'\n",
    ")\n",
    "p = plt.colorbar()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
