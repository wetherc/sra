{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from typing import List, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame({\n",
    "    'sex': ['M', 'M'],\n",
    "    'marital': ['S', 'M'],\n",
    "    'homeowner': ['Y', 'N']\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overlapping Simlarity\n",
    "\n",
    "Given two `n`-dimensional feature vectors, `x` and `y`, overlapping similarity is given by\n",
    "\n",
    "$$\n",
    "s^{O}(x, \\widetilde{x}) = 1 - d^{H}(x, \\widetilde{x})\n",
    "$$\n",
    "\n",
    "where $d^{H}(x, \\widetilde{x})$ is the Hamming distance defined as the number of features that $x$ and $\\widetilde{x}$ do not match, divided by the total number of features:\n",
    "\n",
    "$$\n",
    "d^{H}(x, \\widetilde{x}) = \\frac{\\sum_{i=1}^{n}\\delta(x_{i}, \\widetilde{x}_{i})}{n}\n",
    "$$\n",
    "\n",
    "where\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\delta(x_{i}, \\widetilde{x}_{i}) = \\begin{cases}\n",
    "    1, & x_{i} \\neq \\widetilde{x}_{i} \\\\\n",
    "    0, & x_{i} = \\widetilde{x}_{i}\n",
    "\\end{cases}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "By way of example, in the following dataset we have two feature vectors (i.e., two different observations). Both are male, but differ in marital status and homeowner status:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>marital</th>\n",
       "      <th>homeowner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>S</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sex marital homeowner\n",
       "0   M       S         Y\n",
       "1   M       M         N"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do the pairwise features differ? [False, True, True]\n",
      "Hamming distance between two observations: 0.6666666666666666\n",
      "Overlapping similarity: 0.33333333333333337\n"
     ]
    }
   ],
   "source": [
    "feature_difference = list(data.loc[0,:] != data.loc[1,:])\n",
    "print(f'Do the pairwise features differ? {feature_difference}')\n",
    "\n",
    "hamming_distance = sum(feature_difference) / data.shape[1]\n",
    "print(f'Hamming distance between two observations: {hamming_distance}')\n",
    "\n",
    "overlapping_similarity = 1 - hamming_distance\n",
    "print(f'Overlapping similarity: {overlapping_similarity}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weighted Hamming Distance\n",
    "\n",
    "Rather than averaging across all features in the vector, we can instead use a weighted measure that averages on a per-feature basis with respect to the number of distinct values that the specific feature can take on:\n",
    "$$\n",
    "d^{WH}(x, \\widetilde{x}) = \\sum_{i=1}^{n}\\frac{\\delta(x_{i}, \\widetilde{x}_{i})}{|\\mathcal{D}_{i}|}\n",
    "$$\n",
    "\n",
    "where $|\\mathcal{D}_{i}|$ is the _number_ of distinct possible values that a particular feature is able to assume. (E.g., for homeowner, there would be a cardinality of $2$ since you either are or are not a homeowner.) Applying this weighted distance to the above dataset yields:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of distinct possible values for each feature: [3 2 2]\n",
      "Do the pairwise features differ? [False  True  True]\n",
      "Weighted Hamming distance between two observations: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Note that here I am defining 3 valid values for sex (male,\n",
    "# female, non-binary); 2 for marital status (married, non-married),\n",
    "# and 2 for homeowner status (yes, no)\n",
    "cardinality = np.array([3, 2, 2])\n",
    "print(f'Number of distinct possible values for each feature: {cardinality}')\n",
    "\n",
    "feature_difference = np.array(data.loc[0,:] != data.loc[1,:])\n",
    "print(f'Do the pairwise features differ? {feature_difference}')\n",
    "\n",
    "w_hamming_distance = sum(feature_difference / cardinality)\n",
    "print(f'Weighted Hamming distance between two observations: {w_hamming_distance}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that in the above, we can no longer use the overlapping similarity metric defined previously since our weighted Hamming distance is no longer bounded on a $[0, 1]$ interval.\n",
    "\n",
    "# Extension to a Kernel\n",
    "\n",
    "A kernel function, or a kernel trick, at a high level is a mapping of data into a higher-dimensional, implicit feature space such that we can identify a hyperplane in which our data are linearly separable. Intuitively, the mapping can be visualized as:\n",
    "\n",
    "![](./assets/kernel.png)\n",
    "\n",
    "> Kernel methods apply standard machine learning algorithms that rely on distance metrics or inner products to data embedded into a feature space using kernel functions. The embedding of the data into a feature space is expected to capture and enhance the patterns and regularities in the data. Kernel methods proceed in two steps. The first step embeds the data into a feature space of high or infinite dimension, while the second step uses standard algorithms for classification, clustering, and principal component analysis to detect the regularities of the data in the feature space. The core of kernel methods relies on the use of kernel functions. A kernel function computes the inner product in a feature space of the embedding of two data points under a certain mapping, $\\phi$\n",
    "\n",
    "We can extend our Hamming distance to apply to a Gaussian kernel, by replacing Euclidean distance with it:\n",
    "$$\n",
    "k^{GH}(x, \\widetilde{x}) = e^{-\\frac{\\delta(x, \\widetilde{x})}{2\\sigma^{2}}}\n",
    "$$\n",
    "where $\\sigma > 0$ is a constant kernel width parameter.\n",
    "\n",
    "## Adaptive Gaussian Kernel\n",
    "\n",
    "In the above, $\\sigma$ is a constant parameter. We can, however, use an adaptive bandwidth parameter:\n",
    "$$\n",
    "k^{GH}(x, \\widetilde{x}) = e^{-\\frac{\\delta(x, \\widetilde{x})}{\\beta(x,\\widetilde{x})}}\n",
    "$$\n",
    "where $\\beta(x, \\widetilde{x})$ is an adaptive bandwidth determined by a fixed number of nearest neighbors of data instance $x$ and $\\widetilde{x}$.\n",
    "\n",
    "## Hamming Distance Kernel\n",
    "\n",
    "We can extend the above to a Hamming Distance Kernel, in which we consider $\\mathcal{D}^{n}$ to be the cross product over all $n$ input features. Formally, we can define this by\n",
    "\n",
    "_Let $D_{i}$ by a finite domain of categorical values. Let $(a_{1}, \\ldots, a_{n})$ by a categorical object such that $a_{i}\\in D_{i}$. Let $D^{n}=\\prod_{i=1}^{n}D_{i}$ be the cross product over all the domains of the attributes such that for each $(u_{1}, \\ldots, u_{n})\\in D^{n}$, $u_{i}\\in D_{i}$. Given a categorical object $s = (s_{1}, \\ldots, s_{n})$, $s_{k}$ denotes the value of the $k$-th attribute of $s$_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sex          2\n",
       "marital      2\n",
       "homeowner    2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame({\n",
    "    'sex': ['M', 'M', 'F'],\n",
    "    'marital': ['S', 'M', 'S'],\n",
    "    'homeowner': ['Y', 'N', 'Y']\n",
    "}, dtype='category')\n",
    "data = data.apply(lambda x: x.cat.codes)\n",
    "\n",
    "_cardinality = data.nunique()\n",
    "_cardinality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1.],\n",
       "       [1., 1., 1.],\n",
       "       [1., 1., 1.]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lam = 0.6\n",
    "n = data.shape[0]\n",
    "k_j = np.ones(shape=(n, n))\n",
    "k_j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.515456, 1.9584  , 2.21952 ],\n",
       "       [1.9584  , 2.515456, 1.728   ],\n",
       "       [2.21952 , 1.728   , 2.515456]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for col in range(len(_cardinality)):\n",
    "    dhamming_j = np.not_equal.outer(\n",
    "        data.iloc[:, col].values,\n",
    "        data.iloc[:, col].values\n",
    "    )\n",
    "    k_j = (\n",
    "        (lam**2) * (_cardinality[col]-1-dhamming_j) +\n",
    "        (2*lam-1) * dhamming_j + 1) * k_j\n",
    "    \n",
    "k_j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.6305095, 0.6305095, 0.6305095])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = 1/np.sqrt(np.diag(k_j))\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.77854671 0.88235294]\n",
      " [0.77854671 1.         0.68695298]\n",
      " [0.88235294 0.68695298 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "k_j = k_j * np.outer(d, d)\n",
    "print(k_j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spectral Ranking\n",
    "\n",
    "buckle in, cause this is just a bunch of print statements with not much extra commentary to help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = k_j.shape[0]\n",
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.66089965, 0.        , 0.        ],\n",
       "       [0.        , 2.46549969, 0.        ],\n",
       "       [0.        , 0.        , 2.56930592]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ident = np.zeros((n, n), float)\n",
    "np.fill_diagonal(ident, 1.)\n",
    "\n",
    "# Let D be the degree matrix of each vertex corresponding\n",
    "# the the row sum of the similarity matrix W\n",
    "D = np.zeros((n, n), float)\n",
    "np.fill_diagonal(D, np.sum(k_j, axis=1))\n",
    "D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_inv_sqrt = np.linalg.inv(np.sqrt(D))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let L be the symmetric normalized Laplacian\n",
    "L = ident - np.dot(D_inv_sqrt, k_j).dot(D_inv_sqrt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.62418726, -0.30396106, -0.33745835],\n",
       "       [-0.30396106,  0.59440271, -0.27293965],\n",
       "       [-0.33745835, -0.27293965,  0.61078983]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 0])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract the 2 non-principal eigenvectors.\n",
    "#\n",
    "# The eig() function returns 2 arrays: the\n",
    "# first represents eigenvalues, the second\n",
    "# eigenvectors. The eigenvectors are not\n",
    "# arranged in order of magnitude. We sort\n",
    "# and then sample the second and third vectors\n",
    "eig_vals, eig_vecs = np.linalg.eig(L)\n",
    "eig_vals.argsort()[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.2149818 , -0.77975547],\n",
       "       [-0.79803158,  0.20681425],\n",
       "       [ 0.56296396,  0.59093932]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eig_vecs = eig_vecs[:, eig_vals.argsort()[::][1:]]\n",
    "eig_vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.35068399, -1.25306199,  0.902378  ])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Components of the first non-principal\n",
    "# eigenvectors in the feature space.\n",
    "#\n",
    "# Note that here we're just duplicating\n",
    "# D_sqrt column-wise so that its dimensionality\n",
    "# is equal to that of npeigen\n",
    "z = np.sqrt(np.sum(k_j, axis=1)) * eig_vecs[:, 0]\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1., -1.,  1.])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let C_p be the positive class and and C_n\n",
    "# the negative class assigned based on the\n",
    "# sign of the 1st non-principal eigenvector\n",
    "# component of z\n",
    "C = np.sign(z)\n",
    "C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-1.,  1.]), array([1, 2]))"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C_cnt = np.unique(C, return_counts=True)\n",
    "C_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>-1.0</th>\n",
       "      <th>1.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   -1.0   1.0\n",
       "0     1     2"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C_cnt = pd.DataFrame(\n",
    "    data=np.array(C_cnt[1])[np.newaxis],\n",
    "    columns=C_cnt[0])\n",
    "C_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.35068399,  1.25306199, -0.902378  ])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if C_cnt.iloc[[0]].min(axis=1)[0]/n >= 0.4:\n",
    "    mFLAG = 1\n",
    "    f = np.max(np.abs(z)) - np.abs(z)\n",
    "else:\n",
    "    if C_cnt[1][0] > C_cnt[-1][0]:\n",
    "        mFLAG = 0\n",
    "        f = -z\n",
    "    else:\n",
    "        mFLAG = 0\n",
    "        f = z\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "p = plt.scatter(\n",
    "    x=eig_vecs[:, 1],\n",
    "    y=eig_vecs[:, 0],\n",
    "    c=f,\n",
    "    cmap='seismic'\n",
    ")\n",
    "p = plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.77975547,  0.20681425,  0.59093932])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eig_vecs[:, 1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
